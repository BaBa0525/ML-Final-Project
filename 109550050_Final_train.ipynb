{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Back, Fore, Style\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import HuberRegressor, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data From CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path(\"./dataset\")\n",
    "train = pd.read_csv(basedir / \"train.csv\")\n",
    "test = pd.read_csv(basedir / \"test.csv\")\n",
    "submission = pd.read_csv(basedir / \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train.shape=}\", f\"{test.shape=}\")\n",
    "print(f\"failure 0 : {train[train.failure == 0].shape[0]}\")\n",
    "print(f\"failure 1 : {train[train.failure == 1].shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to predict the missing value of measurement_17\n",
    "fill_dict = {\n",
    "    \"A\": [\"measurement_5\", \"measurement_6\", \"measurement_8\"],\n",
    "    \"B\": [\"measurement_4\", \"measurement_5\", \"measurement_7\"],\n",
    "    \"C\": [\"measurement_5\", \"measurement_7\", \"measurement_8\", \"measurement_9\"],\n",
    "    \"D\": [\"measurement_5\", \"measurement_6\", \"measurement_7\", \"measurement_8\"],\n",
    "    \"E\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_8\"],\n",
    "    \"F\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_7\"],\n",
    "    \"G\": [\"measurement_4\", \"measurement_6\", \"measurement_8\", \"measurement_9\"],\n",
    "    \"H\": [\n",
    "        \"measurement_4\",\n",
    "        \"measurement_5\",\n",
    "        \"measurement_7\",\n",
    "        \"measurement_8\",\n",
    "        \"measurement_9\",\n",
    "    ],\n",
    "    \"I\": [\"measurement_3\", \"measurement_7\", \"measurement_8\"],\n",
    "}\n",
    "\n",
    "feature = [f for f in test.columns if f.startswith(\"measurement\") or f == \"loading\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_any_null(data: pd.DataFrame):\n",
    "    return data.isna().sum(axis=1) == 0\n",
    "\n",
    "def only_target_null(data: pd.Series, feats: list, target: str):\n",
    "    return without_any_null(data[feats]) & data[target].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_column(data: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    for code in data.product_code.unique():\n",
    "        code_data = data[data.product_code == code]\n",
    "        correlation_col = fill_dict[code]\n",
    "\n",
    "        # rows with no empty column\n",
    "        train_fill = code_data[correlation_col + [column_name]].dropna(how=\"any\")\n",
    "        fill_rows_code = only_target_null(code_data, correlation_col, column_name)\n",
    "        fill_data = code_data[fill_rows_code]\n",
    "\n",
    "        model_fill = HuberRegressor()\n",
    "        model_fill.fit(train_fill[correlation_col], train_fill[column_name])\n",
    "\n",
    "        # index in data (global)\n",
    "        fill_rows_data = (data.product_code == code) & only_target_null(\n",
    "            data, correlation_col, column_name\n",
    "        )\n",
    "        data.loc[fill_rows_data, column_name] = model_fill.predict(\n",
    "            fill_data[correlation_col]\n",
    "        )\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(data: pd.DataFrame):\n",
    "    for code in data.product_code.unique():\n",
    "        model_impute = KNNImputer(n_neighbors=5)\n",
    "        # print(f\"KNN imputing code {code}\")\n",
    "        data.loc[(data.product_code == code), feature] = model_impute.fit_transform(\n",
    "            data.loc[(data.product_code == code), feature]\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    data = pd.concat([train, test])\n",
    "    data[\"m3_missing\"] = data[\"measurement_3\"].isnull().astype(np.int8)\n",
    "    data[\"m5_missing\"] = data[\"measurement_5\"].isnull().astype(np.int8)\n",
    "    data[\"measurement_2\"] = data[\"measurement_2\"].clip(15)\n",
    "    data[\"area\"] = data[\"attribute_2\"].values * data[\"attribute_3\"].values\n",
    "    data[\"loading\"] = np.log1p(data[\"loading\"])\n",
    "    data = fill_column(data, \"measurement_17\")\n",
    "    data = impute_data(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(\n",
    "    train_data: pd.DataFrame,\n",
    "    val_data: pd.DataFrame,\n",
    "    test_data: pd.DataFrame,\n",
    "    feats: list,\n",
    "):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaled_train = scaler.fit_transform(train_data[feats])\n",
    "    scaled_val = scaler.transform(val_data[feats])\n",
    "    scaled_test = scaler.transform(test_data[feats])\n",
    "\n",
    "    new_train = train_data.copy()\n",
    "    new_val = val_data.copy()\n",
    "    new_test = test_data.copy()\n",
    "\n",
    "    new_train[feats] = scaled_train\n",
    "    new_val[feats] = scaled_val\n",
    "    new_test[feats] = scaled_test\n",
    "\n",
    "    return new_train, new_val, new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data()\n",
    "copy_train = data[data.failure.notnull()]\n",
    "copy_test = data[data.failure.isnull()]\n",
    "# print(train.shape, test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(feats):\n",
    "    X = copy_train.drop([\"failure\"], axis=1)\n",
    "    y = copy_train[\"failure\"].astype(int)\n",
    "    test = copy_test.drop([\"failure\"], axis=1)\n",
    "\n",
    "    lr_oof = np.zeros(len(X))\n",
    "    lr_test = np.zeros(len(test))\n",
    "    lr_auc = 0\n",
    "    importance_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Fold: {fold_idx}\")\n",
    "        x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        x_test = test.copy()\n",
    "\n",
    "        x_train, x_val, x_test = scale(x_train, x_val, x_test, feats)\n",
    "\n",
    "        model = LogisticRegression(\n",
    "            max_iter=1000, penalty=\"l2\", solver=\"newton-cg\", random_state=42\n",
    "        )\n",
    "        model = AdaBoostClassifier(model, n_estimators=2, learning_rate=0.05)\n",
    "        \n",
    "        model.fit(x_train[feats], y_train)\n",
    "        dump(model, save_path / f\"model_{fold_idx}.joblib\")\n",
    "\n",
    "        val_preds = model.predict_proba(x_val[feats])[:, 1]\n",
    "        lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "        lr_test += model.predict_proba(x_test[feats])[:, 1] / 5\n",
    "        lr_oof[val_idx] = val_preds\n",
    "\n",
    "    print(\n",
    "        f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 5)}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{Fore.RED}{Style.BRIGHT}OOF auc = {round(roc_auc_score(y, lr_oof), 5)}\"\n",
    "    )\n",
    "    return lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature0 = [\"loading\", \"measurement_17\"]\n",
    "feature1 = [\"loading\", \"measurement_17\", \"m3_missing\", \"m5_missing\"]\n",
    "feature2 = [\n",
    "    \"m3_missing\",\n",
    "    \"m5_missing\",\n",
    "    \"measurement_1\",\n",
    "    \"measurement_2\",\n",
    "    \"loading\",\n",
    "    \"measurement_17\",\n",
    "]\n",
    "feature3 = [\n",
    "    \"m3_missing\",\n",
    "    \"m5_missing\",\n",
    "    \"measurement_2\",\n",
    "    \"measurement_3\",\n",
    "    \"loading\",\n",
    "    \"measurement_17\",\n",
    "    \"area\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = train(feature0)\n",
    "lr = train_model(feature1)\n",
    "# lr = train_model(feature2)\n",
    "# lr = train(feature3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['failure'] = lr\n",
    "submission[['id', 'failure']].to_csv('109550050.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Findings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# new_feature = [f for f in test.columns if f.startswith(\"measurement\") and f != \"measurement_17\"]\n",
    "# extract = data[new_feature]\n",
    "\n",
    "# pca = PCA(n_components=1)\n",
    "# new_col = pca.fit_transform(extract)\n",
    "\n",
    "# data[\"c1\"] = new_col[:, 0]\n",
    "# copy_train = data[data.failure.notnull()]\n",
    "# copy_test = data[data.failure.isnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = [\n",
    "#     [[\"C\", \"D\", \"E\"], [\"A\", \"B\"]],\n",
    "#     [[\"B\", \"D\", \"E\"], [\"A\", \"C\"]],\n",
    "#     [[\"B\", \"C\", \"E\"], [\"A\", \"D\"]],\n",
    "#     [[\"B\", \"C\", \"D\"], [\"A\", \"E\"]],\n",
    "#     [[\"A\", \"D\", \"E\"], [\"B\", \"C\"]],\n",
    "#     [[\"A\", \"C\", \"E\"], [\"B\", \"D\"]],\n",
    "#     [[\"A\", \"C\", \"D\"], [\"B\", \"E\"]],\n",
    "#     [[\"A\", \"B\", \"E\"], [\"C\", \"D\"]],\n",
    "#     [[\"A\", \"B\", \"D\"], [\"C\", \"E\"]],\n",
    "#     [[\"A\", \"B\", \"C\"], [\"D\", \"E\"]],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_oof_1 = np.zeros(len(train))\n",
    "# lr_oof_2 = np.zeros(len(train))\n",
    "# lr_test = np.zeros(len(test))\n",
    "# lr_auc = 0\n",
    "# lr_acc = 0\n",
    "# importance_list = []\n",
    "\n",
    "# for (train_code, val_code) in folds:\n",
    "#     train_idx = X[\"product_code\"].isin(train_code)\n",
    "#     val_idx = X[\"product_code\"].isin(val_code)\n",
    "#     x_train = X[train_idx]\n",
    "#     y_train = y[train_idx]\n",
    "#     x_val = X[val_idx]\n",
    "#     y_val = y[val_idx]\n",
    "#     x_test = test.copy()\n",
    "\n",
    "#     x_train, x_val, x_test = scale(x_train, x_val, x_test, select_feature)\n",
    "\n",
    "#     model = LogisticRegression(max_iter=500, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n",
    "#     model.fit(x_train[select_feature], y_train)\n",
    "#     importance_list.append(model.coef_.ravel())\n",
    "\n",
    "#     val_preds = model.predict_proba(x_val[select_feature])[:, 1]\n",
    "#     lr_auc += roc_auc_score(y_val, val_preds) / 10\n",
    "#     y_preds = model.predict(x_val[select_feature])\n",
    "#     lr_acc += accuracy_score(y_val, y_preds) / 10\n",
    "#     lr_test += model.predict_proba(x_test[select_feature])[:, 1] / 10\n",
    "#     lr_oof_1[val_idx] = val_preds\n",
    "#     lr_oof_2[val_idx] = y_preds\n",
    "\n",
    "# print(\n",
    "#     f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 10)}, Average acc = {round(lr_acc, 10)}{Style.RESET_ALL}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"{Fore.RED}{Style.BRIGHT}OOF auc = {round(roc_auc_score(y, lr_oof_1), 10)}, OOF acc = {round(accuracy_score(y, lr_oof_2), 10)}{Style.RESET_ALL}\"\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_feature = [\"loading\", \"measurement_17\", \"m3_missing\", \"m5_missing\"]\n",
    "\n",
    "# X = copy_train.drop([\"failure\"], axis=1)\n",
    "# y = copy_train[\"failure\"].astype(int)\n",
    "# test = copy_test.drop([\"failure\"], axis=1)\n",
    "\n",
    "# lr_oof_1 = np.zeros(len(train))\n",
    "# lr_oof_2 = np.zeros(len(train))\n",
    "# lr2_test = np.zeros(len(test))\n",
    "# lr_auc = 0\n",
    "# lr_acc = 0\n",
    "# importance_list = []\n",
    "# lr_rate = [0.1, 0.01, 0.001]\n",
    "# n_iter = [100, 300, 500]\n",
    "# max_depth = [3, 5, 7, 9]\n",
    "# n_est = [100, 200, 300, 400]\n",
    "\n",
    "# param_grid = dict(max_depth=max_depth, max_iter=n_iter, learning_rate=lr_rate)\n",
    "\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "#     print(f\"Fold: {fold_idx}\")\n",
    "#     x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "#     x_test = test.copy()\n",
    "\n",
    "#     x_train, x_val, x_test = scale(x_train, x_val, x_test, select_feature)\n",
    "\n",
    "#     # model = LogisticRegression(max_iter=100, penalty='l2', solver='newton-cg', random_state=42)\n",
    "#     # model = RandomForestClassifier(n_estimators=5, max_depth=3, random_state=42)\n",
    "#     # model = AdaBoostClassifier(model, n_estimators=100)\n",
    "#     model = HistGradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_iter=60)\n",
    "#     # grid = GridSearchCV(model, param_grid, scoring=)\n",
    "#     # grid_result = grid.fit(x_train[select_feature], y_train)\n",
    "#     # print(f\"最佳準確率: {grid_result.best_score_}，最佳參數組合：{grid_result.best_params_}\")\n",
    "\n",
    "#     # model = AdaBoostClassifier(model, n_estimators=20, learning_rate=0.01, random_state=42)\n",
    "#     # model = HistGradientBoostingClassifier(random_state=42, max_iter=50)\n",
    "#     model.fit(x_train[select_feature], y_train)\n",
    "#     # importance_list.append(model.coef_.ravel())\n",
    "\n",
    "#     val_preds = model.predict_proba(x_val[select_feature])[:, 1]\n",
    "#     lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "#     y_preds = model.predict(x_val[select_feature])\n",
    "#     lr_acc += accuracy_score(y_val, y_preds) / 5\n",
    "#     lr2_test += model.predict_proba(x_test[select_feature])[:, 1] / 5\n",
    "#     lr_oof_1[val_idx] = val_preds\n",
    "#     lr_oof_2[val_idx] = y_preds\n",
    "\n",
    "# print(importance_list)\n",
    "# print(\n",
    "#     f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 5)}, Average acc = {round(lr_acc, 5)}{Style.RESET_ALL}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"{Fore.RED}{Style.BRIGHT}OOF auc = {round(roc_auc_score(y, lr_oof_1), 5)}, OOF acc = {round(accuracy_score(y, lr_oof_2), 5)}{Style.RESET_ALL}\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "972575cad4fff9ef0079c8dec931e4afc42558b08553a4de74f14b0fb80a0580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
